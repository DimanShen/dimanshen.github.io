---
published: true
title: 目标检测（二）：经典算法之 YOLO 与 SSD
category: 目标检测
tags: 
  - 计算机视觉
  - 目标检测
  - One-Stage检测
layout: post
---

One-Stage 目标检测算法不需要经过产生候选区域（Region Proposal）的阶段，直接产生物体的类别概率和位置坐标值，整体流程较 Two-Stage 的目标检测算法更为简单。本文具体讲解 YOLO 和 SSD 这两种经典 One-Stage 目标检测算法。

# YOLO - You Only Look Once

YOLO 是 One-Stage 目标检测算法的开山之作。它将检测问题转化为了回归问题，输入图像只需经过一次处理即可直接获得到物体的类别、Confidence 和坐标位置。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（二）/0.png" alt="0" style="zoom:60%;" />

具体来说，YOLO 将输入图像缩放后划分成 SxS 的网格，每个网格只负责物体中心点落入该网格的物体的检测。每个位置提取 B 个Bounding Box，共提取 S×S×B 个 Box（论文中 S=7，B=2，共 98 个 Box）。每个 Box 预测 5 个回归值，其中 4 个表征位置，第 5 个为 Confidence，反映 Box 包含物体的可能性（注意这里不区分物体的具体类别）以及其认为 Box 预测位置的准确性。即：如果 Bounding Box 不含有物体，Confidence 应该为 0，否则我们希望其尽量接近 Box 与 Ground Truth 的 IoU。此外，每个网格（而非每个 Bounding Box）还要对 C 个类别各预测 1 个条件概率值，代表在网格包含物体的条件下，物体属于某类的概率大小。因此，卷积网络共输出的预测值个数为 (B×5+C)×S×S，之后将使用 NMS（Non-Maximum Suppression，非极大抑制）进行后处理，过滤得到最后的预测框。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（二）/1.jpeg" alt="0" style="zoom:60%;" />

目标检测算法主要分为两个子任务：物体分类和物体定位，故损失也主要包括分类损失和定位损失。常见的损失组合有如下两种：Cls Loss + Loc Loss (SSD 系列算法)、Cls Loss + Obj Loss + Loc Loss (YOLO 系列算法)，即 YOLO 系列算法相比于 SSD 系列算法多了 Object Loss 来判断对应区域是否为物体的损失。此外，YOLO 在损失函数中添加了权重并将长宽取根号以平衡类别不均衡和物体尺寸等带来的影响。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（二）/2.jpeg" alt="0" style="zoom:60%;" />

YOLO 相比于 Two-Stage 的方法速度优势十分明显，在 Titan X 的 GPU  能够达到 45 帧每秒，满足实时性的要求。这不仅源于 One-Stage 的 Regression 机制，也得益于其提取 Bounding Box 的过程：YOLO 对单张图片一共只提取 98 个候选框，而 Faster R-CNN 中 RPN 设计为一个 Sliding Window，对特征图每个位置都回归出 9 个 Anchor，一共约 2w 个 Anchor，通过 NMS 等方法最终会得到约 300 个 Region Proposal，两者之间候选框数量差别巨大，自然效率上会产生差异。另外，YOLO 精简了网络，其卷积网络由 GoogLeNet 更改而来，比 VGG 计算量要稍微小些，可能也会带来效率提升。

此外，相比于基于 Region 的方法，YOLO 的全局处理使得背景错误相对少，而且 YOLO 的泛化性能好，在艺术作品上做人物的检测时其表现要优于 R-CNN。

但 YOLO 本身还是存在一些问题：（1）其划分网格的方式较为粗糙，每个网格只预测两个框，且只做一次物体类别的预测，这限制了对小尺寸群体物体和相近物体的检测；（2）当同一类物体出现不常见的长宽比时，YOLO 的泛化能力偏弱；（3）损失函数中，定位误差是影响检测效果的主要原因，尤其在大小物体的处理上，YOLO 还需进一步加强。

# SSD - Single Shot Multibox Detector

SSD 检测算法的 Backbone 为 VGG 网络，与 YOLO 相比，其主要不同点在于：

（1）SSD 使用多尺度（不同卷积层、不同分辨率）的 Feature Map 进行预测，从下图中网络结构可以看出，其将不同卷积层的特征都输出到最终的检测层，这有利于弥补 YOLO 中对小尺寸物体检测精度较低的问题；

（2）SSD 在每个网格也会生成更多不同大小和长宽比例的 Bounding box，并对每个 Box（而不是每个网格下的多个 Box 共用）进行类别概率的预测。每层卷积网络输出的预测值个数为 (C+4)×K×M×N，其中 C 为类别数，K 为 Box 个数，M×N 为 Feature Map 的大小。SSD 在确定正负样本的时候通过 IoU 进行区分，当某一个 Ground Truth 的候选框与 Box 的 IoU 最大且大于某一个阈值的时候，对应 Box 负责检测该 Ground Truth。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（二）/3.png" alt="0" style="zoom:60%;" />

SSD 的突出点在于其利用了多层网络特征，而不仅仅是 FC7 层。此外，SSD 结合了 Faster R-CNN 和 YOLO 不同方面的优点，它既借鉴了 YOLO 将检测问题转化为回归问题的思路，又保留了 Faster R-CNN 的 Anchor机制，只不过它的 Anchor 不是每个位置的精调，而是像 YOLO 一样产生网格，然后在网格上产生 Anchor。由于利用了多层特征，每层 Anchor 的尺寸都不同，因此产生了较多的超参数，增加了模型复杂度和训练难度。

SSD 在达到接近 Two-Stage 模型的精度同时，拥有比 Two-Stage 快一个数量级的速度，因此后续有很多 One-Stage 的工作都基于 SSD 展开。此外，Two-Stage 和 One-Stage 的模型也都在互相借鉴并吸收彼此的长处，随着目标检测算法的发展，两者的界限变得越来越模糊。