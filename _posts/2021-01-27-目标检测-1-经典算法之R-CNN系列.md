---
published: true
title: 目标检测（一）：经典算法之 R-CNN 系列
category: 目标检测
tags: 
  - 计算机视觉
  - 目标检测
  - Two-Stage检测
layout: post
---

本文首先介绍什么是目标检测，并概述基于深度学习的两种目标检测算法思路，然后具体讲解 R-CNN、Fast R-CNN 和 Faster R-CNN 等 Two-Stage 目标检测算法。

# 目标检测

在说目标检测之前，我们先来说说图像分类。图像分类是最基础的计算机视觉任务，也是深度学习模型最先取得突破和实现大规模应用的任务。ImageNet 是图像分类任务最权威的评测集，每年的 ILSVRC 催生了大量的优秀深度网络结构，为其他任务提供了基础。

图像分类关心图片整体，给出的是整张图片的内容描述，而目标检测给出的是对图片前景和背景的理解，即目标检测需要找出图像中所有感兴趣的物体，包含物体分类和物体定位两个子任务，同时确定物体的类别和位置。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（一）/0.png" alt="0" style="zoom:80%;" />

目标检测任务可分为两个关键的子任务：目标分类和目标定位。目标分类任务负责判断输入图像中是否有感兴趣类别的物体出现，输出一系列带分数的标签表明感兴趣类别的物体出现在输入图像中的可能性。目标定位任务负责确定输入图像中感兴趣类别物体的位置，输出物体的中心或 Bounding Box 等，Bounding Box 一般是矩形的检测框。

目前主流的目标检测算法主要是基于深度学习模型，可以分成两大类：（1）One-Stage 目标检测算法。这类方法不需要经过产生候选区域（Region Proposal）的阶段，直接产生物体的类别概率和位置坐标值，比较典型的算法有 YOLO、SSD 等；（2）Two-Stage 目标检测算法。这类方法将检测问题划分为两个阶段，首先产生候选区域，然后对候选区域进行分类和位置精修，典型代表是基于 Region Proposal 的 R-CNN 系列算法，包括 R-CNN、Fast R-CNN 和 Faster R-CNN 等。

目标检测模型的主要性能指标是检测准确度和速度。对于准确度，目标检测要同时考虑物体的分类以及定位准确度。一般情况下，Two-Stage 算法在准确度上有优势，而 One-Stage 算法在速度上有优势，不过随着研究的发展，两类算法都在两个方面做改进，均能在准确度以及速度上取得较好的结果。

接下来，本文将对 Two-Stage 目标检测算法的典型代表，即 R-CNN 系列算法进行介绍。如果想详细了解 YOLO 和 SSD 等 One-Stage 的检测算法，请阅读下一篇 [目标检测（二）：经典算法之 YOLO 与 SSD](https://dimanshen.github.io/目标检测/2021/02/02/目标检测-2-经典算法之YOLO与SSD/)。

# R-CNN：R-CNN 系列的开山之作

在 R-CNN 中，生成 Proposals 用的是传统方法 Selective Search，而神经网络（论文中采用当时表现最好的分类网络 AlexNet）实际上只是一个特征提取器。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（一）/1.png" alt="0" style="zoom:60%;" />

R-CNN 具体算法过程如下：（1）通过 Selective Search，基于图像中的纹理、边缘、颜色等信息对图像进行自底向上的分割，并对分割区域进行不同尺度的合并，如下图所示，最后提取出约 2k 个自下而上的 Region Proposals；（2）通过神经网络对每个 Region Proposal 做卷积操作，提取 FC7 这一层的特征进行分类（论文中采用 SVM 分类）和坐标回归，调整 Region Proposal 区域。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（一）/2.jpeg" alt="0" style="zoom:70%;" />

R-CNN 的很多做法广泛地影响着检测任务上的深度模型革命。首先，此文提出了一种有效的特征提取和利用方式，通过 CNN 获取图像特征取得的效果超出了手工设计的特征，故后续工程实践中常用 FC7 层特征来做目标分类和定位。此外，R-CNN 采用在 ImageNet 上预训练好的分类模型 AlexNet 作为 Backbone，在检测问题上 Fine-tuning 后取得了很好的效果。这种先在大规模数据集上预训练一个通用网络模型，然后针对具体任务 Fine-tuning，以解决监督训练样本不足的做法也在后续工作中一直沿用。

然而，R-CNN 模型本身还是存在很多问题，如：（1）R-CNN 对于提取 Proposal、目标分类、坐标回归需要分别训练三个不同的模型，不支持 End-to-End 的训练；（2）R-CNN 对每个 Region Proposal 都要单独做卷积运算提取特征，重复计算过多导致效率低下，此外训练阶段产生的大量特征需要写到磁盘，空间代价也很大。因此，后续很多工作都是针对改进这一工作而展开。

# Fast R-CNN：共享卷积计算 by RoI Pooling

Fast R-CNN 与 R-CNN 不同的是：（1）Fast R-CNN 不会对每个 Region Proposal 都单独提取一次特征，而是将 Backbone 在图片整体上运行，为整张图片提取特征，然后将特征传入 R-CNN 子网络，用坐标映射的方式为 Region Proposal 获取特征。这样一张图片只需要过一次网络，共享了大部分计算，极大程度提升了训练和测试速度，故有 Fast 之名；（2）Fast R-CNN 将除 Region Proposal 提取以外的部分都用一个网络来实现，用 Softmax 分类器替换 SVM，并将分类和坐标回归的损失统一起来形成 multi-loss，通过反向传播可以更新所有网络层参数。

其中第（1）点是通过 RoI Pooling实现的（RoI: Region of Interest，同 Region Proposal 的概念类似）：Region Proposals 常常有不同的大小，在映射到 Feature Map 上之后，会得到不同大小的特征张量。RoI Pooling 会将每个不同大小的特征张量都分成相等个数的网格，再在每个网格上进行 Max Pooling，故不同大小的 RoI 区域经过 RoI Pooling 后会得到等长的 RoI 特征向量。实际上第（1）点的做法除了速度快，还有另一个好处：每个 RoI 区域的特征受感受野􏰁的影响，能融合相邻背景的特征，这样可以“看”得更远一些。

下图是Fast R-CNN的网络架构：

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（一）/3.jpeg" alt="0" style="zoom:70%;" />

Fast R-CNN 的贡献之处在于将 Proposal、特征提取、 目标分类和坐标回归统一在一个整体的结构中，并通过共享卷积计算提高特征利用效率。然而，Fast R-CNN 仍有不足之处：其依然采用 Selective Search 算法在原图上获取 Region Proposals，而在共享卷积计算之后，Selective Search 成为了限制 Fast R-CNN 效率的瓶颈，算法仍无法实现实时计算。

# Faster R-CNN：End-to-End 实时检测 by RPN

下图是Faster R-CNN的网络架构。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（一）/4.png" alt="0" style="zoom:30%;" />

粗略的讲，Faster R-CNN = RPN + Fast R-CNN。由于 Selective Search 导致 Fast R-CNN 算法没有实时性的可能，因此 Faster R-CNN 提出用 RPN（Regional Proposal Network）取代 Selective Search 获取 Region Proposal，使得检测任务可以由神经网络 End-to-End 地完成。由于 RPN 与 Fast R-CNN 共享 Conv 特征提取层，故并不会引入太多额外计算􏰀。实验结果表明，这样做同时提高了速度和准确率： Faster R-CNN 可以在单个 GPU 上以 5fps 的速度运行，而在精度方面达到 SOTA（State of the Art）。

<img src="https://raw.githubusercontent.com/DimanShen/dimanshen.github.io/master/_posts/image/目标检测（一）/5.png" alt="0" style="zoom:40%;" />

RPN 是 Faster R-CNN 的精华所在，其网络由卷积层（和 Fast R-CNN 共用，特征提取）和全连接层（分类层 & 回归层）等两部分构成：如上图所示，RPN 在经过卷积计算得到的 Feature Map 上使用 Sliding Window，探索每个 3x3 的特征区域，生成不同大小和长宽比例的 k 个 Anchor（论文中 k = 9），然后为每个 Anchor 输出分类以及坐标回归结果。其中，分类结果为一个概率值，代表这个 Anchor 有目标的概率（每个 Anchor 的分类 label 正负取决于 Anchor 和 Ground Truth 的 IoU 大于或小于设定的 IoU 阈值），回归结果为四个坐标值，用于回归目标的位置。最后将二分类和坐标回归的损失统一起来，作为 RPN 网络的目标训练。

我们可以认为：经过 RPN 的概率值筛选后留存的 Anchors + 坐标回归 = Region Proposals，后续流程则和 Fast R-CNN 类似：Region Proposals 被传入 R-CNN 子网络，进行分类和坐标回归，同样用 multi-loss 将二者的损失联合进行训练。

Faster R-CNN 的成功之处在于用 RPN 网络完成了检测任务的"深度化"。通过 Sliding Window 生成 Anchor 的思想在后来的工作中越来越多地被采用（YOLO v2等），RPN + R-CNN 的 Two-Stage 网络结构影响了大部分后续工作。

目标检测系列的下一篇文章将介绍 YOLO 和 SSD 这两个典型的 One-Stage 目标检测算法。